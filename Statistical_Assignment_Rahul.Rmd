---
title: 'Assignment: 7089 CEM – Introduction to Statistical Methods for Data Science'
author:
  name: Rahul Karn
  id: '250163'
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 2
  pdf_document:
    toc: true
    toc_depth: '2'
  word_document:
    toc: true
    toc_depth: '2'
faculty: Faculty of Engineering, Environment and Computing
---

# installing Package
```{r}
install.packages("kableExtra", repos = "https://cran.rstudio.com/")
install.packages("DT", repos = "https://cran.rstudio.com/")
```

# Setup and Package Loading and storing plots on folder
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, error = FALSE)

library(ggplot2)
library(dplyr)
library(knitr)
library(GGally)
library(reshape2)
library(tidyr)
library(kableExtra)  
library(DT)
library(knitr)

# Define output directories for plots consistently
base_output_dir <- "./assignment_outputs"
if (!dir.exists(base_output_dir)) {
  dir.create(base_output_dir)
}
output_plot_dir_task1 <- file.path(base_output_dir, "task1_plots")
if (!dir.exists(output_plot_dir_task1)) {
  dir.create(output_plot_dir_task1)
}
output_plot_dir_task2 <- file.path(base_output_dir, "task2_plots")
if (!dir.exists(output_plot_dir_task2)) {
  dir.create(output_plot_dir_task2)
}
output_plot_dir_task2_7 <- file.path(base_output_dir, "task2_7_plots")
if (!dir.exists(output_plot_dir_task2_7)) {
  dir.create(output_plot_dir_task2_7)
}
output_plot_dir_task3 <- file.path(base_output_dir, "task3_plots")
if (!dir.exists(output_plot_dir_task3)) {
  dir.create(output_plot_dir_task3)
}

# Define dataset path
dataset_path <- "D:/MSCxAsign/stats/dataset.csv" # Placeholder, user must change
data <- read.csv(dataset_path,
                 stringsAsFactors = FALSE,
                 header = TRUE)
```

# Data Loading and Initial Exploration

```{r}
#First few rows of the dataset
head(data)

```
```{r}
#Structure of the dataset
str(data)
```

```{r}
#Summary statistics of the dataset
summary(data)
```

```{r}
#Checking for missing values per column
colSums(is.na(data))
```

#Data Preprocessing (Normalization)
Normalizing the predictor variables (x1, x3, x4, x5) using Z-score standardization. The dependent variable (x2, Energy Output) will remain in its original scale.

```{r}
# Creating a copy of the data to store the normalized version
data_normalized <- data

# List of predictor columns to normalize
predictor_columns <- c("x1", "x3", "x4", "x5")

# Apply Z-score normalization (scale function in R does this by default)
scaled_predictors <- scale(data[, predictor_columns])
data_normalized[, predictor_columns] <- as.data.frame(scaled_predictors)
head(data_normalized)
```
```{r}
#Summary statistics of the normalized dataset (summary for predictors should show mean ~0, sd ~1)
summary(data_normalized)
```


# Task 1: Preliminary data analysis:

For Task 1, we typically use the **original, unnormalized data** to understand actual distributions and relationships in their original scales.

## 1. Time series plots (of input and output signal)

Assuming the data is ordered by time, we create an index for the x-axis.

```{r task1_time_series_inputs, fig.cap="Time Series Plots of Input Variables"}
library(reshape2)
library(ggplot2)

# add index
data$Index <- seq_len(nrow(data))

# melt only inputs
inputs_melted <- melt(
  data[, c("Index","x1","x3","x4","x5")],
  id.vars = "Index",
  variable.name = "Input", value.name = "Value"
)

# plot inputs
p_inputs <- ggplot(inputs_melted, aes(x = Index, y = Value, color = Input)) +
  geom_line(show.legend = FALSE) +
  facet_wrap(~ Input, scales = "free_y", ncol = 1) +
  labs(
    title = "",
    x     = "Time",
    y     = ""
  ) +
  theme_minimal(base_size = 13)

print(p_inputs)
ggsave(
  filename = file.path(output_plot_dir_task1, "time_series_inputs.png"),
  plot     = p_inputs,
  width    = 8, height = 15
)


```

```{r}
# melt only output
output_melted <- melt(
  data[, c("Index","x2")],
  id.vars = "Index",
  variable.name = "Output", value.name = "Value"
)

# plot output
p_output <- ggplot(output_melted, aes(x = Index, y = Value)) +
  geom_line(color = "#3366CC") +
  labs(
    title = "",
    x     = "Time",
    y     = "Energy Output (MW)"
  ) +
  theme_minimal(base_size = 13)

print(p_output)
ggsave(
  filename = file.path(output_plot_dir_task1, "time_series_output.png"),
  plot     = p_output,
  width    = 8, height = 4
)

```


## 2. Distribution for each signal

Histograms and density plots for each variable.

```{r task1_distribution_plots}
variables_for_dist <- c("x1", "x2", "x3", "x4", "x5")

for (col_name in variables_for_dist) {
  hist_plot <- ggplot(data, aes_string(x = col_name)) +
    geom_histogram(aes(y = ..density..), binwidth = (max(data[[col_name]], na.rm=TRUE) - min(data[[col_name]], na.rm=TRUE)) / 30, fill = "skyblue", color = "black") +
    geom_density(alpha = .2, fill = "#FF6666") +
    labs(title = paste("Histogram and density plot of", col_name),
         x = paste(col_name , " Signal"),
         y = "Density") +
    theme_minimal()
  print(hist_plot) # Display in notebook
  ggsave(file.path(output_plot_dir_task1, paste0("distribution_", col_name, ".png")), plot = hist_plot, width = 8, height = 6)
}
```


## 3. Correlation and Scatter Plots

Examine dependencies between input and output signals.

```{r task1_scatter_plots_enhanced, message=FALSE, warning=FALSE}
library(ggplot2)

# 1) Combine into one data.frame directly from data_normalized
df <- data.frame(
  Y  = data_normalized$x2,   # your response variable
  X1 = data_normalized$x1,
  X3 = data_normalized$x3,
  X4 = data_normalized$x4,
  X5 = data_normalized$x5
)

# 2) Compute & save correlation matrix
cor_mat <- cor(df, use = "complete.obs")
write.csv(
  cor_mat,
  file.path(output_plot_dir_task1, "correlation_matrix.csv"),
  row.names = TRUE
)

# 3) Enhanced scatter + LM plots in a loop
point_col <- "#2C3E50"
line_col  <- "#E74C3C"
vars      <- c("X1", "X3", "X4", "X5")

for (v in vars) {
  p <- ggplot(df, aes_string(x = v, y = "Y")) +
    geom_point(color = point_col, size = 3, alpha = 0.7) +
    geom_smooth(
      method   = "lm",
      se       = TRUE,
      fill     = scales::alpha(line_col, 0.2),
      color    = line_col,
      linetype = "dashed",
      size     = 1
    ) +
    labs(
      title = paste0(v, " vs Y"),
      x     = paste0(v, " Signal"),
      y     = "Output Signal (Y)"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      plot.title       = element_text(face = "bold", hjust = 0.5),
      axis.title       = element_text(face = "bold"),
      panel.grid.major = element_line(color = "grey90", linetype = "dotted"),
      panel.grid.minor = element_blank()
    )

  print(p)

  ggsave(
    filename = file.path(output_plot_dir_task1, paste0(v, "_vs_Y.png")),
    plot     = p,
    width    = 8,
    height   = 6
  )
}

```

# Task 2: Regression – modelling the relationship between gene expression 

This section covers Tasks 2.1 through 2.7. We will use the `data_normalized` (predictors Z-score scaled, target x2 original scale) for fitting models.

## Model Definitions

As per the assignment brief (and user clarification):

*   **Model 1:** `y = θ₁·x₄ + θ₂·x₃² + θ_bias`
*   **Model 2:** `y = θ₁·x₄ + θ₂·x₃² + θ₃·x₅ + θ_bias`
*   **Model 3:** `y = θ₁·x₃ + θ₂·x₄ + θ₃·x₅³`
*   **Model 4:** `y = θ₁·x₄ + θ₂·x₃² + θ₃·x₅³ + θ_bias`
*   **Model 5:** `y = θ₁·x₄ + θ₂·x₁² + θ₃·x₃² + θ_bias`

Where `y` is `x2`.


```{r task2_model_definitions}
model_formulas <- list(
  M1 = x2 ~ x4 + I(x3^2),
  M2 = x2 ~ x4 + I(x3^2) + x5,
  M3 = x2 ~ 0 + x3 + x4 + I(x5^3), # Corrected: No intercept
  M4 = x2 ~ x4 + I(x3^2) + I(x5^3),
  M5 = x2 ~ x4 + I(x1^2) + I(x3^2)
)
model_names <- names(model_formulas)
results_list <- list()

n_obs <- nrow(data_normalized) # Number of observations
print(paste("Using 'data_normalized' for model fitting. Number of observations (n):", n_obs))
```
## 1.  Estimate model parameters
```{r task2_1_params_all}
# Model M1
fit_M1   <- lm(model_formulas[["M1"]], data = data_normalized)
coefs_M1 <- coef(fit_M1)
df_M1 <- data.frame(
  Parameter = names(coefs_M1),
  Estimate  = round(as.numeric(coefs_M1), 4),
  stringsAsFactors = FALSE
)

cat("\n\n### Model M1 – Estimated Parameters (θ̂)\n")
kable(
  df_M1,
  format     = "html",
  caption    = "Table: Model M1 Parameter Estimates",
  col.names  = c("Parameter (θ̂)", "Estimate"),
  table.attr = 'style="width:60%;margin-left:0;"'
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width        = FALSE,
    font_size         = 16,
    position          = "left"
  )

# ----- Model M2 -----
fit_M2   <- lm(model_formulas[["M2"]], data = data_normalized)
coefs_M2 <- coef(fit_M2)
df_M2 <- data.frame(
  Parameter = names(coefs_M2),
  Estimate  = round(as.numeric(coefs_M2), 4),
  stringsAsFactors = FALSE
)

cat("\n\n### Model M2 – Estimated Parameters (θ̂)\n")
kable(
  df_M2,
  format     = "html",
  caption    = "Table: Model M2 Parameter Estimates",
  col.names  = c("Parameter (θ̂)", "Estimate"),
  table.attr = 'style="width:60%;margin-left:0;"'
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width        = FALSE,
    font_size         = 16,
    position          = "left"
  )

# ----- Model M3 -----
fit_M3   <- lm(model_formulas[["M3"]], data = data_normalized)
coefs_M3 <- coef(fit_M3)
df_M3 <- data.frame(
  Parameter = names(coefs_M3),
  Estimate  = round(as.numeric(coefs_M3), 4),
  stringsAsFactors = FALSE
)

cat("\n\n### Model M3 – Estimated Parameters (θ̂)\n")
kable(
  df_M3,
  format     = "html",
  caption    = "Table: Model M3 Parameter Estimates",
  col.names  = c("Parameter (θ̂)", "Estimate"),
  table.attr = 'style="width:60%;margin-left:0;"'
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width        = FALSE,
    font_size         = 16,
    position          = "left"
  )

# ----- Model M4 -----
fit_M4   <- lm(model_formulas[["M4"]], data = data_normalized)
coefs_M4 <- coef(fit_M4)
df_M4 <- data.frame(
  Parameter = names(coefs_M4),
  Estimate  = round(as.numeric(coefs_M4), 4),
  stringsAsFactors = FALSE
)

cat("\n\n### Model M4 – Estimated Parameters (θ̂)\n")
kable(
  df_M4,
  format     = "html",
  caption    = "Table: Model M4 Parameter Estimates",
  col.names  = c("Parameter (θ̂)", "Estimate"),
  table.attr = 'style="width:60%;margin-left:0;"'
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width        = FALSE,
    font_size         = 16,
    position          = "left"
  )
# ----- Model M5 -----
fit_M5   <- lm(model_formulas[["M5"]], data = data_normalized)
coefs_M5 <- coef(fit_M5)
df_M5 <- data.frame(
  Parameter = names(coefs_M5),
  Estimate  = round(as.numeric(coefs_M5), 4),
  stringsAsFactors = FALSE
)

cat("\n\n### Model M5 – Estimated Parameters (θ̂)\n")
kable(
  df_M5,
  format     = "html",
  caption    = "Table: Model M5 Parameter Estimates",
  col.names  = c("Parameter (θ̂)", "Estimate"),
  table.attr = 'style="width:60%;margin-left:0;"'
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width        = FALSE,
    font_size         = 16,
    position          = "left"
  )

```


## 2. Compute the model residual and RSS
```{r task2_2_rss_single_table, message=FALSE, warning=FALSE}
library(DT)

# 1) Compute RSS for each model
rss_df <- data.frame(
  Model = model_names,
  RSS   = sapply(model_names, function(m) {
    fit <- lm(model_formulas[[m]], data = data_normalized)
    round(sum(residuals(fit)^2), 3)
  }),
  stringsAsFactors = FALSE
)

# 2) Render as a single DT table, aligned and with no extra controls
datatable(
  rss_df,
  rownames = FALSE,
  caption  = htmltools::tags$caption(
    style = 'caption-side: top; text-align: left; font-weight:bold;',
    'Table: Task 2.2 – Residual Sum of Squares (RSS) by Model'
  ),
  options = list(
    dom        = 't',         # table only
    ordering   = FALSE,       # disable sorting
    scrollX    = TRUE,        # horizontal scroll if needed
    columnDefs = list(
      list(className = 'dt-left',  targets = 0),  # Model column left-align
      list(className = 'dt-right', targets = 1)   # RSS column right-align
    )
  ),
  class = 'stripe hover'
)


```
## 3. Compute the log-likelihood function
```{r task2_3_loglik_single_table, message=FALSE, warning=FALSE}
library(DT)

# 1) Compute σ̂² and log‐likelihood for each model
n_obs <- nrow(data_normalized)

stats_df <- data.frame(
  Model = model_names,
  SigmaSqHat = sapply(model_names, function(m) {
    fit <- lm(model_formulas[[m]], data = data_normalized)
    rss <- sum(residuals(fit)^2)
    round(rss / (n_obs - 1), 3)
  }),
  LogLikelihood = sapply(model_names, function(m) {
    fit <- lm(model_formulas[[m]], data = data_normalized)
    rss <- sum(residuals(fit)^2)
    sigma2 <- rss / (n_obs - 1)
    ll <- - (n_obs/2) * log(2 * pi) -
          (n_obs/2) * log(sigma2) -
          rss / (2 * sigma2)
    round(ll, 2)
  }),
  stringsAsFactors = FALSE
)

# 2) Render as a single, non‐paginated, aligned DT table
datatable(
  stats_df,
  rownames = FALSE,
  caption  = htmltools::tags$caption(
    style = 'caption-side: top; text-align: left; font-weight:bold;',
    'Table: Task 2.3 – σ̂² and Log‐Likelihood by Model'
  ),
  options = list(
    dom        = 't',       # table only
    ordering   = FALSE,     # disable sorting
    scrollX    = TRUE,      # horizontal scroll if needed
    columnDefs = list(
      list(className = 'dt-left',  targets = 0),  # Model
      list(className = 'dt-right', targets = 1),  # SigmaSqHat
      list(className = 'dt-right', targets = 2)   # LogLikelihood
    )
  ),
  class = 'stripe hover'
)

```
## 4. Compute AIC and BIC
```{r task2_4_aic_bic_table, message=FALSE, warning=FALSE}
library(DT)

# 1) Compute AIC and BIC for each model
aicbic_df <- data.frame(
  Model = model_names,
  AIC   = sapply(model_names, function(m) {
    fit <- lm(model_formulas[[m]], data = data_normalized)
    round(AIC(fit), 3)
  }),
  BIC   = sapply(model_names, function(m) {
    fit <- lm(model_formulas[[m]], data = data_normalized)
    round(BIC(fit), 3)
  }),
  stringsAsFactors = FALSE
)

# 2) Render as a single, non‐paginated, aligned DT table
datatable(
  aicbic_df,
  rownames = FALSE,
  caption  = htmltools::tags$caption(
    style = 'caption-side: top; text-align: left; font-weight:bold;',
    'Table: Task 2.4 – AIC and BIC by Model'
  ),
  options = list(
    dom        = 't',       # table only
    ordering   = FALSE,     # disable sorting
    scrollX    = TRUE,      # horizontal scroll if needed
    columnDefs = list(
      list(className = 'dt-left',  targets = 0),  # Model left-align
      list(className = 'dt-right', targets = 1:2) # AIC and BIC right-align
    )
  ),
  class = 'stripe hover'
)

```
## 5. Check the distribution of model prediction errors 

```{r task2_5_residual_diagnostics, message=FALSE, warning=FALSE}
library(ggplot2)

# Ensure the output directory exists
output_plot_dir_task2 <- "output/task2"
if (!dir.exists(output_plot_dir_task2)) {
  dir.create(output_plot_dir_task2, recursive = TRUE)
}

# Task 2.5: Residual diagnostics for each model
for (model_name in model_names) {
  # Fit the model
  fit      <- lm(model_formulas[[model_name]], data = data_normalized)
  res_vec  <- residuals(fit)
  
  # 1) Histogram + density of residuals
  hist_p <- ggplot(data.frame(res = res_vec), aes(x = res)) +
    geom_histogram(aes(y = ..density..),
                   binwidth = (max(res_vec) - min(res_vec)) / 30,
                   fill    = "skyblue", color = "black") +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    labs(
      title = paste("Residuals Histogram —", model_name),
      x     = "Residuals",
      y     = "Density"
    ) +
    theme_minimal(base_size = 14)
  print(hist_p)
  ggsave(
    filename = file.path(output_plot_dir_task2, paste0("residuals_hist_", model_name, ".png")),
    plot     = hist_p,
    width    = 8,
    height   = 6
  )
  
  # 2) Q–Q plot of residuals
  qq_p <- ggplot(data.frame(res = res_vec), aes(sample = res)) +
    stat_qq() +
    stat_qq_line() +
    labs(
      title = paste("Q–Q Plot of Residuals —", model_name),
      x     = "Theoretical Quantiles",
      y     = "Sample Quantiles"
    ) +
    theme_minimal(base_size = 14)
  print(qq_p)
  ggsave(
    filename = file.path(output_plot_dir_task2, paste0("residuals_qq_", model_name, ".png")),
    plot     = qq_p,
    width    = 8,
    height   = 6
  )
}



```
## 6. Select best regression model 

```{r task2_6_select_fixed, message=FALSE, warning=FALSE}
# Task 2.6: Select best model by AIC, BIC, and residual diagnostics

# 1) Compute AIC/BIC table if not already in scope
if (!exists("aicbic_df")) {
  aicbic_df <- data.frame(
    Model = model_names,
    AIC   = sapply(model_names, function(m) round(AIC(lm(model_formulas[[m]], data_normalized)), 3)),
    BIC   = sapply(model_names, function(m) round(BIC(lm(model_formulas[[m]], data_normalized)), 3)),
    stringsAsFactors = FALSE
  )
}

# 2) Identify which model has the lowest AIC and BIC
best_by_aic <- aicbic_df$Model[ which.min(aicbic_df$AIC) ]
best_by_bic <- aicbic_df$Model[ which.min(aicbic_df$BIC) ]

# 3) Print out the selections
cat("Model with lowest AIC:", best_by_aic, "\n")
cat("Model with lowest BIC:", best_by_bic, "\n\n")

# 4) Compute residual skewness & kurtosis for each model
resid_stats <- data.frame(
  Model    = model_names,
  Skewness = sapply(model_names, function(m) {
    res <- residuals(lm(model_formulas[[m]], data = data_normalized))
    round(mean((res - mean(res))^3)/sd(res)^3, 3)
  }),
  Kurtosis = sapply(model_names, function(m) {
    res <- residuals(lm(model_formulas[[m]], data = data_normalized))
    round(mean((res - mean(res))^4)/sd(res)^4, 3)
  }),
  stringsAsFactors = FALSE
)

cat("Residual diagnostics (Skewness, Kurtosis):\n")
print(resid_stats)
cat("\n")

# 5) Final choice
suggested_best_model <- best_by_aic
cat("Based on lowest AIC & BIC and the residuals closest to normal, we select", 
    suggested_best_model, "as the best model.\n")

```


## 7. Train/Test Split, Parameter Estimation, Predictions & 95% Confidence Intervals
```{r task2_7_train_test_ci, message=FALSE, warning=FALSE, fig.width=12, fig.height=6}
# Task 2.7: Train/Test Split, Fit Best Model, Predictions + 95% CI

library(ggplot2)

# Ensure n_obs and output directory are defined
n_obs <- nrow(data_normalized)
output_plot_dir_task2_7 <- "output/task2_7"
if (!dir.exists(output_plot_dir_task2_7)) {
  dir.create(output_plot_dir_task2_7, recursive = TRUE)
}

# --- USER: MODIFY THIS LINE with your chosen model name from Task 2.6 --- #
chosen_model_name_task2_7 <- if (
  exists("suggested_best_model") &&
  !is.null(suggested_best_model) &&
  suggested_best_model %in% names(model_formulas)
) {
  suggested_best_model
} else {
  "M1"
}
# --- END USER MODIFICATION --- #

cat("\nProceeding with Task 2.7 for the selected best model:", chosen_model_name_task2_7, "\n\n")

if (!chosen_model_name_task2_7 %in% names(model_formulas)) {
  stop("Error: '", chosen_model_name_task2_7,
       "' is not a valid model name (M1–M5).")
}
best_model_formula <- model_formulas[[chosen_model_name_task2_7]]
cat("Formula for the chosen model (", chosen_model_name_task2_7, "): ",
    deparse(best_model_formula), "\n\n", sep="")

# Split data: 70% training, 30% testing
set.seed(123)
train_indices <- sample(seq_len(n_obs), size = floor(0.7 * n_obs))
train_data <- data_normalized[train_indices, ]
test_data  <- data_normalized[-train_indices, ]

cat("Data split:\n",
    "  Training samples:", nrow(train_data), "\n",
    "  Testing samples: ", nrow(test_data), "\n\n", sep=" ")

# 1) Fit the chosen model on training data
cat("Fitting model", chosen_model_name_task2_7, "on training data...\n")
fit_train <- lm(best_model_formula, data = train_data)

cat("\nSummary of fitted model:\n")
print(summary(fit_train))

cat("\nEstimated parameters (θ̂):\n")
print(coef(fit_train))

# 2) Predict on testing data
cat("\nComputing predictions on the testing set...\n")
pred_test <- predict(fit_train, newdata = test_data)

# 3) 95% confidence intervals for predictions
cat("Computing 95% confidence intervals...\n")
ci_test <- predict(fit_train,
                   newdata = test_data,
                   interval = "confidence",
                   level = 0.95)

# Prepare data.frame for plotting
results_plot_df <- data.frame(
  Index       = seq_len(nrow(test_data)),
  Actual      = test_data$x2,
  Predicted   = pred_test,
  CI_Lower    = ci_test[, "lwr"],
  CI_Upper    = ci_test[, "upr"]
)

cat("\nFirst few rows of actuals, predictions, and CIs:\n")
print(head(results_plot_df))

# Plot: Predictions with 95% CI ribbon and actual points
prediction_ci_plot <- ggplot(results_plot_df, aes(x = Index)) +
  geom_ribbon(aes(ymin = CI_Lower, ymax = CI_Upper),
              fill = "skyblue", alpha = 0.3) +
  geom_line(aes(y = Predicted), color = "blue", size = 1) +
  geom_point(aes(y = Actual), color = "darkred", alpha = 0.6) +
  labs(
    title = paste("Predictions ±95% CI on Test Set — Model", chosen_model_name_task2_7),
    x     = "Test Sample Index",
    y     = "Energy Output (x2)"
  ) +
  theme_minimal(base_size = 14)
print(prediction_ci_plot)
ggsave(
  file.path(output_plot_dir_task2_7, paste0("predictions_ci_plot_", chosen_model_name_task2_7, ".png")),
  plot  = prediction_ci_plot,
  width = 12, height = 6
)

# Plot: Actual vs. Predicted
actual_vs_predicted_plot <- ggplot(results_plot_df, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = paste("Actual vs. Predicted — Model", chosen_model_name_task2_7),
    x     = "Actual x2",
    y     = "Predicted x2"
  ) +
  coord_fixed() +
  theme_minimal(base_size = 14)
print(actual_vs_predicted_plot)
ggsave(
  file.path(output_plot_dir_task2_7, paste0("actual_vs_predicted_plot_", chosen_model_name_task2_7, ".png")),
  plot  = actual_vs_predicted_plot,
  width = 8, height = 6
)



```

# Task 3 - Approximate Bayesian Computation (ABC)

```{r task3_abc}
# --- USER: MODIFY THIS LINE with your chosen model name from Task 2.6 --- #
chosen_model_name_abc <- if(exists("suggested_best_model") && !is.null(suggested_best_model) && suggested_best_model %in% names(model_formulas)) { suggested_best_model } else { "M1" } # Defaults to suggested_best_model (if valid) or M1 as a fallback.
# --- END USER MODIFICATION --- #
cat(paste("\nProceeding with Task 3 for the selected best model:", chosen_model_name_abc, "\n"))

if (!chosen_model_name_abc %in% names(model_formulas)){
  stop(paste("Error: Chosen model name for ABC '", chosen_model_name_abc, "' is not a valid model name (M1-M5). Please check."))
}
selected_model_formula_abc <- model_formulas[[chosen_model_name_abc]]

# Fit the selected model on the FULL dataset to get OLS estimates (as per Task 2.1)
cat(paste("Refitting the selected model (", chosen_model_name_abc, ") on the full dataset to get OLS parameters...\n"))
ols_fit_full_data <- lm(selected_model_formula_abc, data = data_normalized)
ols_params_full_data <- coef(ols_fit_full_data)

cat("OLS parameters for the selected model on full data:\n")
print(ols_params_full_data)

# Identify 2 Parameters with Largest Absolute OLS Values
param_names <- names(ols_params_full_data)
slope_params <- ols_params_full_data
if ("(Intercept)" %in% param_names) { # Exclude intercept from candidates for ABC if it exists
  slope_params <- ols_params_full_data[param_names != "(Intercept)"]
}
if(length(slope_params) < 2) {
  stop("The selected model has less than 2 slope parameters (excluding intercept). ABC task requires 2.")
}
top_two_params_names <- names(sort(abs(slope_params), decreasing = TRUE)[1:2])
cat("The two parameters selected for ABC (largest absolute OLS slope values):\n")
print(top_two_params_names)

param1_ols_val <- ols_params_full_data[top_two_params_names[1]]
param2_ols_val <- ols_params_full_data[top_two_params_names[2]]
fixed_params_ols <- ols_params_full_data[!names(ols_params_full_data) %in% top_two_params_names]
cat("Fixed parameters (using OLS estimates):\n")
print(fixed_params_ols)

# --- USER: Define Uniform Prior Ranges --- #
# Example: OLS value +/- 50% or a fixed sensible range. Adjust these carefully!
param1_prior_min <- param1_ols_val - 0.5 * abs(param1_ols_val) 
param1_prior_max <- param1_ols_val + 0.5 * abs(param1_ols_val)
if (param1_prior_min == param1_prior_max) { param1_prior_min <- param1_ols_val - 1; param1_prior_max <- param1_ols_val + 1; }
if (param1_prior_min > param1_prior_max) { temp <- param1_prior_min; param1_prior_min <- param1_prior_max; param1_prior_max <- temp; }

param2_prior_min <- param2_ols_val - 0.5 * abs(param2_ols_val)
param2_prior_max <- param2_ols_val + 0.5 * abs(param2_ols_val)
if (param2_prior_min == param2_prior_max) { param2_prior_min <- param2_ols_val - 1; param2_prior_max <- param2_ols_val + 1; }
if (param2_prior_min > param2_prior_max) { temp <- param2_prior_min; param2_prior_min <- param2_prior_max; param2_prior_max <- temp; }
# --- END USER MODIFICATION FOR PRIORS --- #

cat(paste("Uniform prior for", top_two_params_names[1], ": U(", param1_prior_min, ",", param1_prior_max, ")\n"))
cat(paste("Uniform prior for", top_two_params_names[2], ": U(", param2_prior_min, ",", param2_prior_max, ")\n"))

# --- USER: Define ABC Parameters --- #
N_simulations <- 10000 # Number of simulations
observed_rss_ols <- sum(residuals(ols_fit_full_data)^2)
epsilon <- observed_rss_ols * 1.05 # Tolerance: e.g., 5% larger than OLS RSS. Adjust carefully!
# --- END USER MODIFICATION FOR ABC PARAMS --- #

cat(paste("Number of ABC simulations:", N_simulations, "\n"))
cat(paste("Observed RSS from OLS fit (full data):", observed_rss_ols, "\n"))
cat(paste("ABC acceptance tolerance (epsilon for RSS):", epsilon, "\n"))

accepted_samples <- data.frame()
X_matrix_full <- model.matrix(ols_fit_full_data)
observed_y <- data_normalized$x2

for (i in 1:N_simulations) {
  current_param1_sample <- runif(1, min = param1_prior_min, max = param1_prior_max)
  current_param2_sample <- runif(1, min = param2_prior_min, max = param2_prior_max)
  
  current_all_params_sim <- fixed_params_ols
  current_all_params_sim[top_two_params_names[1]] <- current_param1_sample
  current_all_params_sim[top_two_params_names[2]] <- current_param2_sample
  
  param_vector_for_pred_sim <- numeric(ncol(X_matrix_full))
  names(param_vector_for_pred_sim) <- colnames(X_matrix_full)
  for(p_name_sim in names(param_vector_for_pred_sim)){
    if(p_name_sim %in% names(current_all_params_sim)){
      param_vector_for_pred_sim[p_name_sim] <- current_all_params_sim[p_name_sim]
    }
  }
  
  simulated_y <- X_matrix_full %*% param_vector_for_pred_sim
  simulated_rss <- sum((observed_y - simulated_y)^2)
  
  if (simulated_rss < epsilon) {
    accepted_samples <- rbind(accepted_samples, data.frame(
      param1_val = current_param1_sample,
      param2_val = current_param2_sample,
      rss = simulated_rss
    ))
  }
  if (i %% (N_simulations/10) == 0) {
    cat(paste("ABC Simulation", i, "/", N_simulations, "- Accepted:", nrow(accepted_samples), "\r"))
    flush.console()
  }
}
cat(paste("\nABC complete. Total accepted samples:", nrow(accepted_samples), "\n"))

if (nrow(accepted_samples) == 0) {
  cat("No samples accepted. Try increasing N_simulations or epsilon, or check prior ranges.\n")
} else {
  colnames(accepted_samples) <- c(top_two_params_names[1], top_two_params_names[2], "RSS")

  cat("Generating posterior distribution plots...\n")
  
  # Joint posterior
  joint_posterior_plot <- ggplot(accepted_samples, aes(x = .data[[ top_two_params_names[1] ]], y = .data[[ top_two_params_names[2] ]])) +
    geom_point(alpha = 0.5) +
    labs(title = paste("Joint Posterior for", top_two_params_names[1], "&", top_two_params_names[2]),
         x = top_two_params_names[1], y = top_two_params_names[2]) +
    theme_minimal()
  print(joint_posterior_plot)
  ggsave(file.path(output_plot_dir_task3, "joint_posterior.png"), plot = joint_posterior_plot, width = 8, height = 7)

  # Marginal posterior for param1
  marginal_param1_plot <- ggplot(accepted_samples, aes(x = .data[[ top_two_params_names[1] ]])) +
    geom_histogram(aes(y = ..density..), fill = "skyblue", color = "black", bins = 30) +
    geom_density(alpha = .2, fill = "#FF6666") +
    labs(title = paste("Marginal Posterior for", top_two_params_names[1]), x = top_two_params_names[1], y = "Density") +
    theme_minimal()
  print(marginal_param1_plot)
  ggsave(file.path(output_plot_dir_task3, paste0("marginal_posterior_", top_two_params_names[1], ".png")), plot = marginal_param1_plot, width = 8, height = 6)

  # Marginal posterior for param2
  marginal_param2_plot <- ggplot(accepted_samples, aes(x = .data[[ top_two_params_names[2] ]])) +
    geom_histogram(aes(y = ..density..), fill = "lightgreen", color = "black", bins = 30) +
    geom_density(alpha = .2, fill = "#FF6666") +
    labs(title = paste("Marginal Posterior for", top_two_params_names[2]), x = top_two_params_names[2], y = "Density") +
    theme_minimal()
  print(marginal_param2_plot)
  ggsave(file.path(output_plot_dir_task3, paste0("marginal_posterior_", top_two_params_names[2], ".png")), plot = marginal_param2_plot, width = 8, height = 6)

#  if (nrow(accepted_samples) > 1) {
#    posterior_pairs_plot <- ggpairs(accepted_samples[, c(top_two_params_names[1], top_two_params_names[2])],
#                                    title = "Joint and Marginal Posteriors from ABC")
#    print(posterior_pairs_plot)
#    ggsave(file.path(output_plot_dir_task3, "posterior_pairs_plot.png"), plot = posterior_pairs_plot, width = 10,  #height = 10)
#  }
  cat(paste("Posterior plots saved to", output_plot_dir_task3, "\n"))
}
cat("Task 3 (ABC) script complete.\n")
```
# session info
```{r session_info}
sessionInfo()
```
```
#End of Assignment.




